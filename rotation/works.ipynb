{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# reader.py\n",
    "## typeraisedのconverterエラーチェック用\n",
    "    - typeraisedがread_parsedtreeで読み込めない。\n",
    "        - combinatorsに'>T'が含まれていなかったことが原因"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Iterator, List, Tuple\n",
    "# import re\n",
    "\n",
    "from depccg.cat import Category\n",
    "from depccg.tree import Tree\n",
    "from depccg.types import Token\n",
    "from depccg.tools.reader import ReaderResult\n",
    "\n",
    "\n",
    "combinators = {\n",
    "    'SSEQ', '>', '<', '>B', '<B1', '<B2', '<B3',\n",
    "    '<B4', '>Bx1', '>Bx2', '>Bx3',\n",
    "    'ADNext', 'ADNint', 'ADV0', 'ADV1', 'ADV2', '>T'\n",
    "}\n",
    "\n",
    "# DEPENDENCY = re.compile(r'{.+?}')\n",
    "\n",
    "\n",
    "def read_parsedtree(line: str) -> Iterator[ReaderResult]:\n",
    "    \"\"\"read the file of the Japanese CCG derivations parsed by depccg.\n",
    "\n",
    "    Args:\n",
    "        filename (str): file name string\n",
    "\n",
    "    Yields:\n",
    "        Iterator[ReaderResult]: iterator object containing parse results\n",
    "    \"\"\"\n",
    "    i = 1\n",
    "    line = line.strip()\n",
    "    tree, tokens = ParsedJaCCGLineReader(line).parse()\n",
    "    yield ReaderResult(str(i), tokens, tree)\n",
    "\n",
    "\n",
    "class ParsedJaCCGLineReader(object):\n",
    "    def __init__(self, line: str) -> None:\n",
    "        self.line = line\n",
    "        self.index = 0\n",
    "        self.word_id = -1\n",
    "        self.tokens = []\n",
    "\n",
    "    def next(self, target: str) -> str:\n",
    "        end = self.line.find(target, self.index)\n",
    "        result = self.line[self.index:end]\n",
    "        self.index = end + 1\n",
    "        return result\n",
    "\n",
    "    def check(self, text: str, offset: int = 0) -> None:\n",
    "        if self.line[self.index + offset] != text:\n",
    "            raise RuntimeError('AutoLineReader.check catches parse error')\n",
    "\n",
    "    def peek(self) -> str:\n",
    "        return self.line[self.index]\n",
    "\n",
    "    def parse(self) -> Tuple[Tree, List[Token]]:\n",
    "        result = self.next_node()\n",
    "        return result, self.tokens\n",
    "\n",
    "    @property\n",
    "    def next_node(self):\n",
    "        end = self.line.find(' ', self.index)\n",
    "        if self.line[self.index + 1:end] in combinators:\n",
    "            return self.parse_tree\n",
    "        else:\n",
    "            return self.parse_leaf\n",
    "\n",
    "    def parse_leaf(self) -> Tree:\n",
    "        self.word_id += 1\n",
    "        self.check('{')\n",
    "        cat = self.next(' ')[1:]\n",
    "        # cat = cat[:cat.find('_')]\n",
    "        # cat = DEPENDENCY.sub('', cat)\n",
    "        cat = Category.parse(cat)\n",
    "        surf, base, pos1, pos2 = self.next('}')[:-1].split('/')\n",
    "        token = Token(surf=surf, base=base, pos1=pos1, pos2=pos2)\n",
    "        self.tokens.append(token)\n",
    "        return Tree.make_terminal(surf, cat)\n",
    "\n",
    "    def parse_tree(self) -> Tree:\n",
    "        self.check('{')\n",
    "        op_string = self.next(' ')\n",
    "        # cat = DEPENDENCY.sub('', self.next(' '))\n",
    "        cat = self.next(' ')\n",
    "        cat = Category.parse(cat)\n",
    "        self.check('{')\n",
    "\n",
    "        children = []\n",
    "        while self.peek() != '}':\n",
    "            children.append(self.next_node())\n",
    "            if self.peek() == ' ':\n",
    "                self.next(' ')\n",
    "\n",
    "        self.next('}')\n",
    "\n",
    "        if len(children) == 1:\n",
    "            return Tree.make_unary(cat, children[0], op_string.replace(\"{\", \"\"), op_string.replace(\"{\", \"\"))\n",
    "        else:\n",
    "            assert len(\n",
    "                children) == 2, f'failed to parse, invalid number of children: {self.line}'\n",
    "            left, right = children\n",
    "            return Tree.make_binary(cat, left, right, op_string.replace(\"{\", \"\"), op_string.replace(\"{\", \"\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = r\"{< S[mod=nm,form=stem,fin=t] {> S[mod=nm,form=stem,fin=f] {ADV0 S[mod=X1,form=X2,fin=X3]/S[mod=X1,form=X2,fin=X3] {< NP[case=nc,mod=adv,fin=f] {> NP[case=nc,mod=adv,fin=f] {< NP[case=X1,mod=X2,fin=f]/NP[case=X1,mod=X2,fin=f] {> NP[case=nc,mod=nm,fin=f] {NP[case=X1,mod=X2,fin=f]/NP[case=X1,mod=X2,fin=f] ９/９/名詞-数/_} {NP[case=nc,mod=nm,fin=f] ５/５/名詞-数/_}} {(NP[case=X1,mod=X2,fin=f]/NP[case=X1,mod=X2,fin=f])\\NP[case=nc,mod=nm,fin=f] ―/―/記号-一般/_}} {< NP[case=nc,mod=adv,fin=f] {> NP[case=nc,mod=nm,fin=f] {NP[case=X1,mod=X2,fin=f]/NP[case=X1,mod=X2,fin=f] ９/９/名詞-数/_} {NP[case=nc,mod=nm,fin=f] ７/７/名詞-数/_}} {NP[case=nc,mod=adv,fin=f]\\NP[case=nc,mod=nm,fin=f] 年/年/名詞-接尾-助数詞/_}}} {NP[case=X1,mod=X2,fin=f]\\NP[case=X1,mod=X2,fin=f] 、/、/記号-読点/_}}} {> S[mod=nm,form=stem,fin=f] {ADV0 S[mod=X1,form=X2,fin=X3]/S[mod=X1,form=X2,fin=X3] {< S[mod=adv,form=cont,fin=f] {< S[mod=adv,form=cont,fin=f] {< NP[case=ni,mod=nm,fin=f] {> NP[case=nc,mod=nm,fin=f] {< NP[case=X1,mod=X2,fin=f]/NP[case=X1,mod=X2,fin=f] {NP[case=X1,mod=X2,fin=f]/NP[case=X1,mod=X2,fin=f] 中国/中国/名詞-固有名詞-地域-国/_} {(NP[case=X1,mod=X2,fin=f]/NP[case=X1,mod=X2,fin=f])\\(NP[case=X1,mod=X2,fin=f]/NP[case=X1,mod=X2,fin=f]) ・/・/記号-一般/_}} {NP[case=nc,mod=nm,fin=f] 北京大/北京大/名詞-固有名詞-組織/_}} {NP[case=ni,mod=nm,fin=f]\\NP[case=nc,mod=nm,fin=f] に/に/助詞-格助詞-一般/_}} {<B1 S[mod=adv,form=cont,fin=f]\\NP[case=ni,mod=nm,fin=f] {S[mod=nm,form=stem,fin=f]\\NP[case=ni,mod=nm,fin=f] 留学/留学/名詞-サ変接続/_} {S[mod=adv,form=cont,fin=f]\\S[mod=nm,form=stem,fin=f] し/し/動詞-自立/連用形-サ変・スル}}} {S[mod=X1,form=X2,fin=f]\\S[mod=X1,form=X2,fin=f] 、/、/記号-読点/_}}} {> S[mod=nm,form=stem,fin=f] {< S[mod=X1,form=X2,fin=f]/S[mod=X1,form=X2,fin=f] {< NP[case=nc,mod=nm,fin=f] {NP[case=nc,mod=nm,fin=f] 帰国/帰国/名詞-サ変接続/_} {NP[case=nc,mod=nm,fin=f]\\NP[case=nc,mod=nm,fin=f] 後/後/名詞-接尾-副詞可能/_}} {(S[mod=X1,form=X2,fin=f]/S[mod=X1,form=X2,fin=f])\\NP[case=nc,mod=nm,fin=f] に/に/助詞-格助詞-一般/_}} {< S[mod=nm,form=stem,fin=f] {< NP[case=o,mod=nm,fin=f] {NP[case=nc,mod=nm,fin=f] 双子/双子/名詞-一般/_} {NP[case=o,mod=nm,fin=f]\\NP[case=nc,mod=nm,fin=f] を/を/助詞-格助詞-一般/_}} {S[mod=nm,form=stem,fin=f]\\NP[case=o,mod=nm,fin=f] 出産/出産/名詞-サ変接続/_}}}}} {S[mod=nm,form=stem,fin=t]\\S[mod=nm,form=stem,fin=f] 。/。/記号-句点/_}}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ADV0'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trees = [tree for _, _, tree in read_parsedtree(s)]\n",
    "tree = trees[0]\n",
    "tree\n",
    "tree.left_child.left_child.op_symbol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<depccg.tree.Tree at 0x11ac33550>"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = r\"{> S[mod=nm,form=base,fin=f] {>T S[mod=X1,form=X2,fin=X3]/(S[mod=X1,form=X2,fin=X3]\\NP[case=X1,mod=X2,fin=X3]) {< NP[case=ga,mod=nm,fin=f] {NP[case=nc,mod=nm,fin=f] 太郎/太郎/_/_} {NP[case=ga,mod=nm,fin=f]\\NP[case=nc,mod=nm,fin=f] が/が/_/_}}} {> S[mod=nm,form=base,fin=f]\\NP[case=ga,mod=nm,fin=f] {>T (S[mod=X1,form=X2,fin=X3]\\NP[case=X1,mod=X2,fin=X3])/((S[mod=X1,form=X2,fin=X3]\\NP[case=X1,mod=X2,fin=X3])\\NP[case=X1,mod=X2,fin=X3]) {< NP[case=o,mod=nm,fin=f] {NP[case=nc,mod=nm,fin=f] 花子/花子/_/_} {NP[case=o,mod=nm,fin=f]\\NP[case=nc,mod=nm,fin=f] を/を/_/_}}} {<B2 (S[mod=nm,form=base,fin=f]\\NP[case=ga,mod=nm,fin=f])\\NP[case=o,mod=nm,fin=f] {(S[mod=nm,form=cont,fin=f]\\NP[case=ga,mod=nm,fin=f])\\NP[case=o,mod=nm,fin=f] 殴っ/殴っ/_/_} {S[mod=nm,form=base,fin=f]\\S[mod=nm,form=cont,fin=f] た/た/_/_}}}}\"\n",
    "trees = [tree for _, _, tree in read_parsedtree(s)]\n",
    "tree = trees[0]\n",
    "tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from depccg.cat import Category, Functor, Atom, Feature\n",
    "import re\n",
    "cat_split = re.compile(r'([\\[\\]\\(\\)/\\\\|<>])')\n",
    "punctuations = [',', '.', ';', ':', 'LRB', 'RRB', 'conj', '*START*', '*END*']\n",
    "\n",
    "def parse(text: str) -> 'Category':\n",
    "        tokens = cat_split.sub(r' \\1 ', text)\n",
    "        print('print(tokens)')\n",
    "        print(tokens)\n",
    "        buffer = list(reversed([i for i in tokens.split(' ') if i != '']))\n",
    "        print('print(buffer)')\n",
    "        print(buffer)\n",
    "        print()\n",
    "        stack = []\n",
    "\n",
    "        while len(buffer):\n",
    "            item = buffer.pop()\n",
    "            if item in punctuations:\n",
    "                stack.append(Atom(item))\n",
    "                print('if item in punctuations')\n",
    "                print(buffer)\n",
    "                print(stack)\n",
    "                print()\n",
    "            elif item in '(<':\n",
    "                stack.append(item)\n",
    "                print('elif item in (<')\n",
    "                print(buffer)\n",
    "                print(stack)\n",
    "                print()\n",
    "            elif item in ')>':\n",
    "                y = stack.pop()\n",
    "                # case like: stack = [\"(\", S/NP], buffer = [\")\"]\n",
    "                # which can occur when parsing eg., \"((S/NP))\"\n",
    "                print('elif item in >)')\n",
    "                print(buffer)\n",
    "                print(stack)\n",
    "                print()\n",
    "                assert len(stack) > 0\n",
    "                if (\n",
    "                    stack[-1] == '(' and item == ')'\n",
    "                    or stack[-1] == '<' and item == '>'\n",
    "                ):\n",
    "                    assert stack.pop() in \"(<\"\n",
    "                    stack.append(y)\n",
    "                    print('if item in stack[-1] == ( and item == ) or stack[-1] == < and item == >')\n",
    "                    print(buffer)\n",
    "                    print(stack)\n",
    "                    print()\n",
    "                # case like: stack = [\"(\", S, /, NP], buffer = [\")\"]\n",
    "                else:\n",
    "                    f = stack.pop()\n",
    "                    x = stack.pop()\n",
    "                    assert stack.pop() in \"(<\"\n",
    "                    stack.append(Functor(x, f, y))\n",
    "                    print('else:(if item in stack[-1] == ( and item == ) or stack[-1] == < and item == >)')\n",
    "                    print(buffer)\n",
    "                    print(stack)\n",
    "                    print()\n",
    "            elif item in '/\\\\|':\n",
    "                stack.append(item)\n",
    "            else:\n",
    "                # cases to process atomic category\n",
    "                # 1. when there is a feature eg., buffer = [\"[\", \"dcl\", \"]\"]\n",
    "                if len(buffer) >= 3 and buffer[-1] == '[':\n",
    "                    buffer.pop()\n",
    "                    feature = Feature.parse(buffer.pop())\n",
    "                    assert buffer.pop() == ']'\n",
    "                    stack.append(Atom(item, feature))\n",
    "                    print('else if len(buffer) >= 3')\n",
    "                    print(buffer)\n",
    "                    print(stack)\n",
    "                    print()\n",
    "                # 2. case with no feature\n",
    "                else:\n",
    "                    stack.append(Atom(item))\n",
    "                    print('else')\n",
    "                    print('stack.append(Atom(item))')\n",
    "                    print(buffer)\n",
    "                    print(stack)\n",
    "                    print()\n",
    "        if len(stack) == 1:\n",
    "                return stack[0]\n",
    "        try:\n",
    "                x, f, y = stack\n",
    "                return Functor(x, f, y)\n",
    "        except ValueError:\n",
    "                raise RuntimeError(f'falied to parse category: {text}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "print(tokens)\n",
      "S [ mod=X1,form=X2,fin=X3 ]  /  ( S [ mod=X1,form=X2,fin=X3 ]  \\ NP [ case=X1,mod=X2,fin=X3 ]  ) \n",
      "print(buffer)\n",
      "[')', ']', 'case=X1,mod=X2,fin=X3', '[', 'NP', '\\\\', ']', 'mod=X1,form=X2,fin=X3', '[', 'S', '(', '/', ']', 'mod=X1,form=X2,fin=X3', '[', 'S']\n",
      "\n",
      "else if len(buffer) >= 3\n",
      "[')', ']', 'case=X1,mod=X2,fin=X3', '[', 'NP', '\\\\', ']', 'mod=X1,form=X2,fin=X3', '[', 'S', '(', '/']\n",
      "[S[mod=X1,form=X2,fin=X3]]\n",
      "\n",
      "elif item in (<\n",
      "[')', ']', 'case=X1,mod=X2,fin=X3', '[', 'NP', '\\\\', ']', 'mod=X1,form=X2,fin=X3', '[', 'S']\n",
      "[S[mod=X1,form=X2,fin=X3], '/', '(']\n",
      "\n",
      "else if len(buffer) >= 3\n",
      "[')', ']', 'case=X1,mod=X2,fin=X3', '[', 'NP', '\\\\']\n",
      "[S[mod=X1,form=X2,fin=X3], '/', '(', S[mod=X1,form=X2,fin=X3]]\n",
      "\n",
      "else if len(buffer) >= 3\n",
      "[')']\n",
      "[S[mod=X1,form=X2,fin=X3], '/', '(', S[mod=X1,form=X2,fin=X3], '\\\\', NP[case=X1,mod=X2,fin=X3]]\n",
      "\n",
      "elif item in >)\n",
      "[]\n",
      "[S[mod=X1,form=X2,fin=X3], '/', '(', S[mod=X1,form=X2,fin=X3], '\\\\']\n",
      "\n",
      "else:(if item in stack[-1] == ( and item == ) or stack[-1] == < and item == >)\n",
      "[]\n",
      "[S[mod=X1,form=X2,fin=X3], '/', S[mod=X1,form=X2,fin=X3]\\NP[case=X1,mod=X2,fin=X3]]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "S[mod=X1,form=X2,fin=X3]/(S[mod=X1,form=X2,fin=X3]\\NP[case=X1,mod=X2,fin=X3])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse(r\"S[mod=X1,form=X2,fin=X3]/(S[mod=X1,form=X2,fin=X3]\\NP[case=X1,mod=X2,fin=X3])\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "print(tokens)\n",
      " ( S [ mod=X1,form=X2,fin=X3 ]  \\ NP [ case=X1,mod=X2,fin=X3 ]  )  /  (  ( S [ mod=X1,form=X2,fin=X3 ]  \\ NP [ case=X1,mod=X2,fin=X3 ]  )  \\ NP [ case=X1,mod=X2,fin=X3 ]  ) \n",
      "print(buffer)\n",
      "[')', ']', 'case=X1,mod=X2,fin=X3', '[', 'NP', '\\\\', ')', ']', 'case=X1,mod=X2,fin=X3', '[', 'NP', '\\\\', ']', 'mod=X1,form=X2,fin=X3', '[', 'S', '(', '(', '/', ')', ']', 'case=X1,mod=X2,fin=X3', '[', 'NP', '\\\\', ']', 'mod=X1,form=X2,fin=X3', '[', 'S', '(']\n",
      "\n",
      "elif item in (<\n",
      "[')', ']', 'case=X1,mod=X2,fin=X3', '[', 'NP', '\\\\', ')', ']', 'case=X1,mod=X2,fin=X3', '[', 'NP', '\\\\', ']', 'mod=X1,form=X2,fin=X3', '[', 'S', '(', '(', '/', ')', ']', 'case=X1,mod=X2,fin=X3', '[', 'NP', '\\\\', ']', 'mod=X1,form=X2,fin=X3', '[', 'S']\n",
      "['(']\n",
      "\n",
      "else if len(buffer) >= 3\n",
      "[')', ']', 'case=X1,mod=X2,fin=X3', '[', 'NP', '\\\\', ')', ']', 'case=X1,mod=X2,fin=X3', '[', 'NP', '\\\\', ']', 'mod=X1,form=X2,fin=X3', '[', 'S', '(', '(', '/', ')', ']', 'case=X1,mod=X2,fin=X3', '[', 'NP', '\\\\']\n",
      "['(', S[mod=X1,form=X2,fin=X3]]\n",
      "\n",
      "else if len(buffer) >= 3\n",
      "[')', ']', 'case=X1,mod=X2,fin=X3', '[', 'NP', '\\\\', ')', ']', 'case=X1,mod=X2,fin=X3', '[', 'NP', '\\\\', ']', 'mod=X1,form=X2,fin=X3', '[', 'S', '(', '(', '/', ')']\n",
      "['(', S[mod=X1,form=X2,fin=X3], '\\\\', NP[case=X1,mod=X2,fin=X3]]\n",
      "\n",
      "elif item in >)\n",
      "[')', ']', 'case=X1,mod=X2,fin=X3', '[', 'NP', '\\\\', ')', ']', 'case=X1,mod=X2,fin=X3', '[', 'NP', '\\\\', ']', 'mod=X1,form=X2,fin=X3', '[', 'S', '(', '(', '/']\n",
      "['(', S[mod=X1,form=X2,fin=X3], '\\\\']\n",
      "\n",
      "else:(if item in stack[-1] == ( and item == ) or stack[-1] == < and item == >)\n",
      "[')', ']', 'case=X1,mod=X2,fin=X3', '[', 'NP', '\\\\', ')', ']', 'case=X1,mod=X2,fin=X3', '[', 'NP', '\\\\', ']', 'mod=X1,form=X2,fin=X3', '[', 'S', '(', '(', '/']\n",
      "[S[mod=X1,form=X2,fin=X3]\\NP[case=X1,mod=X2,fin=X3]]\n",
      "\n",
      "elif item in (<\n",
      "[')', ']', 'case=X1,mod=X2,fin=X3', '[', 'NP', '\\\\', ')', ']', 'case=X1,mod=X2,fin=X3', '[', 'NP', '\\\\', ']', 'mod=X1,form=X2,fin=X3', '[', 'S', '(']\n",
      "[S[mod=X1,form=X2,fin=X3]\\NP[case=X1,mod=X2,fin=X3], '/', '(']\n",
      "\n",
      "elif item in (<\n",
      "[')', ']', 'case=X1,mod=X2,fin=X3', '[', 'NP', '\\\\', ')', ']', 'case=X1,mod=X2,fin=X3', '[', 'NP', '\\\\', ']', 'mod=X1,form=X2,fin=X3', '[', 'S']\n",
      "[S[mod=X1,form=X2,fin=X3]\\NP[case=X1,mod=X2,fin=X3], '/', '(', '(']\n",
      "\n",
      "else if len(buffer) >= 3\n",
      "[')', ']', 'case=X1,mod=X2,fin=X3', '[', 'NP', '\\\\', ')', ']', 'case=X1,mod=X2,fin=X3', '[', 'NP', '\\\\']\n",
      "[S[mod=X1,form=X2,fin=X3]\\NP[case=X1,mod=X2,fin=X3], '/', '(', '(', S[mod=X1,form=X2,fin=X3]]\n",
      "\n",
      "else if len(buffer) >= 3\n",
      "[')', ']', 'case=X1,mod=X2,fin=X3', '[', 'NP', '\\\\', ')']\n",
      "[S[mod=X1,form=X2,fin=X3]\\NP[case=X1,mod=X2,fin=X3], '/', '(', '(', S[mod=X1,form=X2,fin=X3], '\\\\', NP[case=X1,mod=X2,fin=X3]]\n",
      "\n",
      "elif item in >)\n",
      "[')', ']', 'case=X1,mod=X2,fin=X3', '[', 'NP', '\\\\']\n",
      "[S[mod=X1,form=X2,fin=X3]\\NP[case=X1,mod=X2,fin=X3], '/', '(', '(', S[mod=X1,form=X2,fin=X3], '\\\\']\n",
      "\n",
      "else:(if item in stack[-1] == ( and item == ) or stack[-1] == < and item == >)\n",
      "[')', ']', 'case=X1,mod=X2,fin=X3', '[', 'NP', '\\\\']\n",
      "[S[mod=X1,form=X2,fin=X3]\\NP[case=X1,mod=X2,fin=X3], '/', '(', S[mod=X1,form=X2,fin=X3]\\NP[case=X1,mod=X2,fin=X3]]\n",
      "\n",
      "else if len(buffer) >= 3\n",
      "[')']\n",
      "[S[mod=X1,form=X2,fin=X3]\\NP[case=X1,mod=X2,fin=X3], '/', '(', S[mod=X1,form=X2,fin=X3]\\NP[case=X1,mod=X2,fin=X3], '\\\\', NP[case=X1,mod=X2,fin=X3]]\n",
      "\n",
      "elif item in >)\n",
      "[]\n",
      "[S[mod=X1,form=X2,fin=X3]\\NP[case=X1,mod=X2,fin=X3], '/', '(', S[mod=X1,form=X2,fin=X3]\\NP[case=X1,mod=X2,fin=X3], '\\\\']\n",
      "\n",
      "else:(if item in stack[-1] == ( and item == ) or stack[-1] == < and item == >)\n",
      "[]\n",
      "[S[mod=X1,form=X2,fin=X3]\\NP[case=X1,mod=X2,fin=X3], '/', (S[mod=X1,form=X2,fin=X3]\\NP[case=X1,mod=X2,fin=X3])\\NP[case=X1,mod=X2,fin=X3]]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(S[mod=X1,form=X2,fin=X3]\\NP[case=X1,mod=X2,fin=X3])/((S[mod=X1,form=X2,fin=X3]\\NP[case=X1,mod=X2,fin=X3])\\NP[case=X1,mod=X2,fin=X3])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse(r\"(S[mod=X1,form=X2,fin=X3]\\NP[case=X1,mod=X2,fin=X3])/((S[mod=X1,form=X2,fin=X3]\\NP[case=X1,mod=X2,fin=X3])\\NP[case=X1,mod=X2,fin=X3])\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# bottom-up traversal for node count\n",
    "## 作業メモ\n",
    "    - binary treeに関しては正しく動くことが確認できた\n",
    "    - unaryを含む文については未確認。\n",
    "        - type-raised treeが、read_parsedtreeでの読み込みに失敗しているため。\n",
    "        - ↑ rebranchingおよびnodecountのために修正必要\n",
    "    - ↑ unaryでもうまくいった。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = r\"{< S[mod=nm,form=base,fin=f] {< NP[case=ga,mod=nm,fin=f] {NP[case=nc,mod=nm,fin=f] 私/私/名詞-代名詞-一般/_} {NP[case=ga,mod=nm,fin=f]\\NP[case=nc,mod=nm,fin=f] が/が/助詞-格助詞-一般/_}} {S[mod=nm,form=base,fin=f]\\NP[case=ga,mod=nm,fin=f] 歩く/歩く/動詞-自立/基本形-五段・カ行イ音便}}\"\n",
    "trees = [tree for _, _, tree in read_parsedtree(s)]\n",
    "tree = trees[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = r\"{< S[mod=nm,form=base,fin=f] {< NP[case=ga,mod=nm,fin=f] {NP[case=nc,mod=nm,fin=f] 太郎/太郎/名詞-固有名詞-人名-名/_} {(NP[case=ga,mod=nm,fin=f]\\NP[case=nc,mod=nm,fin=f]) が/が/助詞-格助詞-一般/_}} {< S[mod=nm,form=base,fin=f]\\NP[case=ga,mod=nm,fin=f] {< NP[case=o,mod=nm,fin=f] {NP[case=nc,mod=nm,fin=f] 花子/花子/名詞-固有名詞-人名-名/_} {(NP[case=o,mod=nm,fin=f]\\NP[case=nc,mod=nm,fin=f]) を/を/助詞-格助詞-一般/_}} {<B2 ((S[mod=nm,form=base,fin=f]\\NP[case=ga,mod=nm,fin=f])\\NP[case=o,mod=nm,fin=f]) {((S[mod=nm,form=cont,fin=f]\\NP[case=ga,mod=nm,fin=f])\\NP[case=o,mod=nm,fin=f]) 殴っ/殴っ/動詞-自立/連用タ接続-五段・ラ行} {(S[mod=nm,form=base,fin=f]\\S[mod=nm,form=cont,fin=f]) た/た/助動詞/基本形-特殊・タ}}}}\"\n",
    "trees = [tree for _, _, tree in read_parsedtree(s)]\n",
    "tree = trees[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = r\"{> S[mod=nm,form=base,fin=f] {>T S[mod=X1,form=X2,fin=X3]/(S[mod=X1,form=X2,fin=X3]\\NP[case=X1,mod=X2,fin=X3]) {< NP[case=ga,mod=nm,fin=f] {NP[case=nc,mod=nm,fin=f] 私/私/_/_} {NP[case=ga,mod=nm,fin=f]\\NP[case=nc,mod=nm,fin=f] が/が/_/_}}} {S[mod=nm,form=base,fin=f]\\NP[case=ga,mod=nm,fin=f] 歩く/歩く/_/_}}\"\n",
    "trees = [tree for _, _, tree in read_parsedtree(s)]\n",
    "tree = trees[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = r\"{> S[mod=nm,form=base,fin=f] {>T S[mod=X1,form=X2,fin=X3]/(S[mod=X1,form=X2,fin=X3]\\NP[case=X1,mod=X2,fin=X3]) {< NP[case=ga,mod=nm,fin=f] {NP[case=nc,mod=nm,fin=f] 太郎/太郎/_/_} {NP[case=ga,mod=nm,fin=f]\\NP[case=nc,mod=nm,fin=f] が/が/_/_}}} {> S[mod=nm,form=base,fin=f]\\NP[case=ga,mod=nm,fin=f] {>T (S[mod=X1,form=X2,fin=X3]\\NP[case=X1,mod=X2,fin=X3])/((S[mod=X1,form=X2,fin=X3]\\NP[case=X1,mod=X2,fin=X3])\\NP[case=X1,mod=X2,fin=X3]) {< NP[case=o,mod=nm,fin=f] {NP[case=nc,mod=nm,fin=f] 花子/花子/_/_} {NP[case=o,mod=nm,fin=f]\\NP[case=nc,mod=nm,fin=f] を/を/_/_}}} {<B2 (S[mod=nm,form=base,fin=f]\\NP[case=ga,mod=nm,fin=f])\\NP[case=o,mod=nm,fin=f] {(S[mod=nm,form=cont,fin=f]\\NP[case=ga,mod=nm,fin=f])\\NP[case=o,mod=nm,fin=f] 殴っ/殴っ/_/_} {S[mod=nm,form=base,fin=f]\\S[mod=nm,form=cont,fin=f] た/た/_/_}}}}\"\n",
    "trees = [tree for _, _, tree in read_parsedtree(s)]\n",
    "tree = trees[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['太郎', 'が', '花子', 'を', '殴っ', 'た'], [1, 3, 1, 3, 1, 4])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Tuple, List\n",
    "\n",
    "from depccg.tree import Tree, Token\n",
    "\n",
    "class NodeCount(object):\n",
    "    def __init__(self):\n",
    "        self.count = 1\n",
    "        self.tokens = []\n",
    "        self.results = []\n",
    "\n",
    "    def traverse(self, node: Tree) -> None:\n",
    "        if node.is_leaf == False:\n",
    "            children = node.children\n",
    "            if len(children) == 1:\n",
    "                self.traverse(children[0])\n",
    "                self.count += 1\n",
    "            else:\n",
    "                self.traverse(children[0])\n",
    "                self.traverse(children[1])\n",
    "                self.count += 1\n",
    "        else:\n",
    "            self.results.append(self.count)\n",
    "            self.count += 1\n",
    "\n",
    "def nodecount(tree: Tree):\n",
    "    nd = NodeCount()\n",
    "    nd.traverse(tree)\n",
    "    nd.results.append(nd.count)\n",
    "    results = [j-i for i,j in zip(nd.results, nd.results[1:])]\n",
    "    tokens = [token['word'] for token in tree.tokens]\n",
    "    return tokens, results\n",
    "\n",
    "nodecount(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/chainer-7.8.1-py3.10.egg/chainer/_environment_check.py:33: UserWarning: Accelerate has been detected as a NumPy backend library.\n",
      "vecLib, which is a part of Accelerate, is known not to work correctly with Chainer.\n",
      "We recommend using other BLAS libraries such as OpenBLAS.\n",
      "For details of the issue, please see\n",
      "https://docs.chainer.org/en/stable/tips.html#mnist-example-does-not-converge-in-cpu-mode-on-mac-os-x.\n",
      "\n",
      "Please be aware that Mac OS X is not an officially supported OS.\n",
      "\n",
      "  warnings.warn('''\\\n",
      "/usr/local/lib/python3.10/site-packages/tqdm-4.64.0-py3.10.egg/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using AllenNLP requires the python packages Spacy, Pytorch and Numpy to be installed. Please see https://github.com/allenai/allennlp for installation instructions.\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'thinc'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 79>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdepccg\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtree\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Tree\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdepccg\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01munification\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Unification\n\u001b[0;32m---> 79\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdepccg\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprinter\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mja\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ja_of\n\u001b[1;32m     81\u001b[0m \u001b[38;5;66;03m# all the original combinators in the Japanese CCGBank\u001b[39;00m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;66;03m#   >, >B, >Bx1, >Bx2, >Bx3,\u001b[39;00m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;66;03m#   <, <B1, <B2, <B3, <B4,\u001b[39;00m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;66;03m#   ADV0, ADV1, ADV2, \u001b[39;00m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;66;03m#   ADNint, ADNext, SSEQ\u001b[39;00m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mTreeRotation\u001b[39;00m(\u001b[38;5;28mobject\u001b[39m):\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/depccg-2.0.3-py3.10-macosx-12-x86_64.egg/depccg/printer/__init__.py:8\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlxml\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m etree\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdepccg\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtree\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ScoredTree\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdepccg\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minstance_models\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SEMANTIC_TEMPLATES\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdepccg\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msemantics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mccg2lambda\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m parse \u001b[38;5;28;01mas\u001b[39;00m ccg2lambda\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdepccg\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlang\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_global_language\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/depccg-2.0.3-py3.10-macosx-12-x86_64.egg/depccg/instance_models.py:9\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdepccg\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtypes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GrammarConfig, ModelConfig\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdepccg\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchainer\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msupertagger\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_chainer_tagger\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdepccg\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mallennlp\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msupertagger\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_allennlp_tagger\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdepccg\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlang\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_global_language\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdepccg\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgrammar\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m en, ja\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/depccg-2.0.3-py3.10-macosx-12-x86_64.egg/depccg/allennlp/supertagger.py:6\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlogging\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mitertools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m islice\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdepccg\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mallennlp\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpredictor\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msupertagger_predictor\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SupertaggerPredictor\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdepccg\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mallennlp\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataset\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mja_supertagging_dataset\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m JaSupertaggingDatasetReader\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdepccg\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mallennlp\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataset\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msupertagging_dataset\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TritrainSupertaggingDatasetReader\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/depccg-2.0.3-py3.10-macosx-12-x86_64.egg/depccg/allennlp/predictor/supertagger_predictor.py:3\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Any, Dict, List\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mallennlp\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m JsonDict\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mallennlp\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DatasetReader, Instance\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mallennlp\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvocabulary\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DEFAULT_OOV_TOKEN, DEFAULT_PADDING_TOKEN\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/allennlp-2.10.0-py3.10.egg/allennlp/__init__.py:11\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m warnings\u001b[38;5;241m.\u001b[39mfilterwarnings(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m, message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy.ufunc size changed\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;66;03m# On some systems this prevents the dreaded\u001b[39;00m\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;66;03m# ImportError: dlopen: cannot load any more object with static TLS\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;241m,\u001b[39m \u001b[38;5;21;01mspacy\u001b[39;00m\u001b[38;5;241m,\u001b[39m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;241m,\u001b[39m \u001b[38;5;21;01mnumpy\u001b[39;00m  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m     15\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing AllenNLP requires the python packages Spacy, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     16\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPytorch and Numpy to be installed. Please see \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     17\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://github.com/allenai/allennlp for installation instructions.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     18\u001b[0m     )\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/spacy-3.3.1-py3.10-macosx-12-x86_64.egg/spacy/__init__.py:11\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m setup_default_warnings()  \u001b[38;5;66;03m# noqa: E402\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# These are imported as part of the API\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mthinc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m prefer_gpu, require_gpu, require_cpu  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mthinc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Config\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pipeline  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'thinc'"
     ]
    }
   ],
   "source": [
    "from typing import Iterator, List, Tuple\n",
    "from depccg.cat import Category\n",
    "from depccg.tree import Tree\n",
    "from depccg.types import Token\n",
    "from depccg.tools.reader import ReaderResult\n",
    "combinators = {\n",
    "    'SSEQ', '>', '<', '>B', '<B1', '<B2', '<B3',\n",
    "    '<B4', '>Bx1', '>Bx2', '>Bx3',\n",
    "    'ADNext', 'ADNint', 'ADV0', 'ADV1', 'ADV2', '>T'\n",
    "}\n",
    "def read_parsedtree(line: str) -> Iterator[ReaderResult]:\n",
    "    i = 1\n",
    "    line = line.strip()\n",
    "    tree, tokens = ParsedJaCCGLineReader(line).parse()\n",
    "    yield ReaderResult(str(i), tokens, tree)\n",
    "class ParsedJaCCGLineReader(object):\n",
    "    def __init__(self, line: str) -> None:\n",
    "        self.line = line\n",
    "        self.index = 0\n",
    "        self.word_id = -1\n",
    "        self.tokens = []\n",
    "    def next(self, target: str) -> str:\n",
    "        end = self.line.find(target, self.index)\n",
    "        result = self.line[self.index:end]\n",
    "        self.index = end + 1\n",
    "        return result\n",
    "    def check(self, text: str, offset: int = 0) -> None:\n",
    "        if self.line[self.index + offset] != text:\n",
    "            raise RuntimeError('AutoLineReader.check catches parse error')\n",
    "    def peek(self) -> str:\n",
    "        return self.line[self.index]\n",
    "    def parse(self) -> Tuple[Tree, List[Token]]:\n",
    "        result = self.next_node()\n",
    "        return result, self.tokens\n",
    "    @property\n",
    "    def next_node(self):\n",
    "        end = self.line.find(' ', self.index)\n",
    "        if self.line[self.index + 1:end] in combinators:\n",
    "            return self.parse_tree\n",
    "        else:\n",
    "            return self.parse_leaf\n",
    "    def parse_leaf(self) -> Tree:\n",
    "        self.word_id += 1\n",
    "        self.check('{')\n",
    "        cat = self.next(' ')[1:]\n",
    "        cat = Category.parse(cat)\n",
    "        surf, base, pos1, pos2 = self.next('}')[:-1].split('/')\n",
    "        token = Token(surf=surf, base=base, pos1=pos1, pos2=pos2)\n",
    "        self.tokens.append(token)\n",
    "        return Tree.make_terminal(surf, cat)\n",
    "    def parse_tree(self) -> Tree:\n",
    "        self.check('{')\n",
    "        op_string = self.next(' ')\n",
    "        # cat = DEPENDENCY.sub('', self.next(' '))\n",
    "        cat = self.next(' ')\n",
    "        cat = Category.parse(cat)\n",
    "        self.check('{')\n",
    "        children = []\n",
    "        while self.peek() != '}':\n",
    "            children.append(self.next_node())\n",
    "            if self.peek() == ' ':\n",
    "                self.next(' ')\n",
    "        self.next('}')\n",
    "        if len(children) == 1:\n",
    "            return Tree.make_unary(cat, children[0], op_string.replace(\"{\", \"\"), op_string.replace(\"{\", \"\"))\n",
    "        else:\n",
    "            assert len(\n",
    "                children) == 2, f'failed to parse, invalid number of children: {self.line}'\n",
    "            left, right = children\n",
    "            return Tree.make_binary(cat, left, right, op_string.replace(\"{\", \"\"), op_string.replace(\"{\", \"\"))\n",
    "########### ↑ read_parsedtree #################\n",
    "\n",
    "\n",
    "from typing import Dict, Optional\n",
    "\n",
    "from depccg.cat import Category\n",
    "from depccg.tree import Tree\n",
    "from depccg.unification import Unification\n",
    "from depccg.printer.ja import ja_of\n",
    "\n",
    "# all the original combinators in the Japanese CCGBank\n",
    "#   >, >B, >Bx1, >Bx2, >Bx3,\n",
    "#   <, <B1, <B2, <B3, <B4,\n",
    "#   ADV0, ADV1, ADV2, \n",
    "#   ADNint, ADNext, SSEQ\n",
    "\n",
    "class TreeRotation(object):\n",
    "    def __init__(self):     \n",
    "        self.cat_to_order: Dict[str, int] = {\n",
    "            '>':0,\n",
    "            '<':0,\n",
    "            '>B':1,\n",
    "            '<B1':1,\n",
    "            '<B2':2,\n",
    "            '<B3':3,\n",
    "            '<B4':4,\n",
    "            '>Bx1':1,\n",
    "            '>Bx2':2,\n",
    "            '>Bx3':3\n",
    "            }\n",
    "        \n",
    "        self.order_to_forwardstring: Dict[int, str] = {\n",
    "            0: 'fa',\n",
    "            1: 'fc',\n",
    "            2: 'fc2'\n",
    "        }\n",
    "        \n",
    "        self.order_to_forwardsymbol: Dict[int, str] = {\n",
    "            0: '>',\n",
    "            1: '>B',\n",
    "            2: '>B2'\n",
    "        }\n",
    "        \n",
    "\n",
    "    def forward(self, cat_symbol: str) -> bool:\n",
    "        return (cat_symbol.startswith('>')) and ('x' not in cat_symbol)\n",
    "    \n",
    "    \n",
    "    def rotate2left(self, node: Tree) -> Tree:\n",
    "        if node.is_leaf:\n",
    "            return node\n",
    "        elif node.is_unary:\n",
    "            return Tree.make_unary(node.cat,\n",
    "                                   self.rotate2left(node.child),\n",
    "                                   node.op_string,\n",
    "                                   node.op_symbol)\n",
    "        else:  # if node is binary\n",
    "            return self.sinkForwardLeftward(Tree.make_binary(node.cat,\n",
    "                                                        self.rotate2left(node.left_child),\n",
    "                                                        self.rotate2left(node.right_child),\n",
    "                                                        node.op_string,\n",
    "                                                        node.op_symbol))\n",
    "    def sinkForwardLeftward(self, top: Tree) -> Tree:\n",
    "        if (top.is_unary == False) and (self.forward(top.op_symbol)):\n",
    "            a = top.left_child\n",
    "            right = top.right_child\n",
    "            def rebuild(x: int, r: Tree) -> Optional[Tree]:\n",
    "                if r.is_unary == False:  # if node is binary,\n",
    "                    y = self.cat_to_order[r.op_symbol]\n",
    "                    b, c = r.children\n",
    "                    if (self.forward(r.op_symbol)) and (x >= y):\n",
    "                        new_order = x-y+1\n",
    "                        newl = rebuild(new_order, b)\n",
    "                        if isinstance(newl, Tree):\n",
    "                            return Tree.make_binary(top.cat,\n",
    "                                                    newl,\n",
    "                                                    c,\n",
    "                                                    r.op_string,\n",
    "                                                    r.op_symbol)\n",
    "                        elif (newl == None) and (new_order <= 2):\n",
    "                            uni = Unification(\"a/b\", \"b/c\")\n",
    "                            uni(a.cat, b.cat)\n",
    "                            newl_cat = Functor(uni[\"a\"], \"/\", uni[\"c\"])\n",
    "                            newl_string = self.order_to_forwardstring[new_order]\n",
    "                            newl_symbol = self.order_to_forwardsymbol[new_order]\n",
    "                            return Tree.make_binary(top.cat,\n",
    "                                                    Tree.make_binary(newl_cat,\n",
    "                                                                    a,\n",
    "                                                                    b,\n",
    "                                                                    newl_string,\n",
    "                                                                    newl_symbol),\n",
    "                                                    c,\n",
    "                                                    r.op_string,\n",
    "                                                    r.op_symbol)\n",
    "                        else:\n",
    "                            return None\n",
    "\n",
    "                    elif (top.op_symbol == '>') and (r.op_symbol == '<') and (re.match(r'(\\(*)NP', str(b.cat)) is not None) and (a.cat.right.base == 'NP') and (c.cat.right.base == 'NP'):\n",
    "                        new_order = x\n",
    "                        newl = rebuild(new_order, b)\n",
    "                        if isinstance(newl, Tree):\n",
    "                            return Tree.make_binary(top.cat,\n",
    "                                                    newl,\n",
    "                                                    c,\n",
    "                                                    'ba',\n",
    "                                                    '<')\n",
    "                        elif newl == None:\n",
    "                            uni = Unification(\"a/b\", \"b\")\n",
    "                            uni(a.cat, b.cat)\n",
    "                            newl_cat = uni[\"a\"]\n",
    "                            return Tree.make_binary(top.cat,\n",
    "                                                    Tree.make_binary(newl_cat,\n",
    "                                                                    a,\n",
    "                                                                    b,\n",
    "                                                                    'fa',\n",
    "                                                                    '>'),\n",
    "                                                    c,\n",
    "                                                    'ba',\n",
    "                                                    '<')\n",
    "                        else:\n",
    "                            return None\n",
    "\n",
    "                    else:\n",
    "                        return None\n",
    "                else:\n",
    "                    return None\n",
    "            rebranch = rebuild(self.cat_to_order[top.op_string],\n",
    "                               right)\n",
    "            \n",
    "            if isinstance(rebranch, Tree):\n",
    "                return rebranch\n",
    "            else:\n",
    "                return top\n",
    "    \n",
    "    @staticmethod\n",
    "    def return_rotated_tree(line):\n",
    "        self = TreeRotation(line)\n",
    "\n",
    "        trees = [tree for _, _, tree in read_parsedtree()]\n",
    "        for tree in trees:\n",
    "            tree = self.rotate2left(tree)\n",
    "            print(ja_of(tree))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # s = r\"{< S[mod=nm,form=base,fin=t] {> S[mod=nm,form=base,fin=f] {< S[mod=X1,form=X2,fin=f]/S[mod=X1,form=X2,fin=f] {< S[mod=X1,form=X2,fin=f]/S[mod=X1,form=X2,fin=f] {> S[mod=nm,form=base,fin=f] {>T S[mod=X1,form=X2,fin=X3]/(S[mod=X1,form=X2,fin=X3]\\NP[case=X1,mod=X2,fin=X3]) {< NP[case=ga,mod=nm,fin=f] {> NP[case=nc,mod=nm,fin=f] {ADNint NP[case=nc,mod=X1,fin=X2]/NP[case=nc,mod=X1,fin=X2] {>Bx1 S[mod=adn,form=base,fin=f]\\NP[case=ga,mod=nm,fin=f] {ADV0 S[mod=X1,form=X2,fin=X3]/S[mod=X1,form=X2,fin=X3] {< S[mod=adv,form=cont,fin=f] {S[mod=nm,form=cont,fin=f] 呼び出し/呼び出し/_/_} {S[mod=adv,form=cont,fin=f]\\S[mod=nm,form=cont,fin=f] て/て/_/_}}} {<B1 S[mod=adn,form=base,fin=f]\\NP[case=ga,mod=nm,fin=f] {S[mod=nm,form=stem,fin=f]\\NP[case=ga,mod=nm,fin=f] 注意/注意/_/_} {S[mod=adn,form=base,fin=f]\\S[mod=nm,form=stem,fin=f] する/する/_/_}}}} {NP[case=nc,mod=nm,fin=f] 先生/先生/_/_}} {NP[case=ga,mod=nm,fin=f]\\NP[case=nc,mod=nm,fin=f] も/も/_/_}}} {<B1 S[mod=nm,form=base,fin=f]\\NP[case=ga,mod=nm,fin=f] {S[mod=nm,form=cont,fin=f]\\NP[case=ga,mod=nm,fin=f] い/い/_/_} {S[mod=nm,form=base,fin=f]\\S[mod=nm,form=cont,fin=f] た/た/_/_}}} {(S[mod=X1,form=X2,fin=f]/S[mod=X1,form=X2,fin=f])\\S[mod=nm,form=base,fin=f] が/が/_/_}} {(S[mod=X1,form=X2,fin=f]/S[mod=X1,form=X2,fin=f])\\(S[mod=X1,form=X2,fin=f]/S[mod=X1,form=X2,fin=f]) 、/、/_/_}} {> S[mod=nm,form=base,fin=f] {>T S[mod=X1,form=X2,fin=X3]/(S[mod=X1,form=X2,fin=X3]\\NP[case=X1,mod=X2,fin=X3]) {< NP[case=ga,mod=nm,fin=f] {> NP[case=nc,mod=nm,fin=f] {ADNint NP[case=nc,mod=X1,fin=X2]/NP[case=nc,mod=X1,fin=X2] {> S[mod=adn,form=base,fin=f] {< S[mod=X1,form=X2,fin=f]/S[mod=X1,form=X2,fin=f] {> NP[case=nc,mod=nm,fin=f] {< NP[case=X1,mod=X2,fin=f]/NP[case=X1,mod=X2,fin=f] {NP[case=X1,mod=X2,fin=f]/NP[case=X1,mod=X2,fin=f] 二/二/_/_} {(NP[case=X1,mod=X2,fin=f]/NP[case=X1,mod=X2,fin=f])\\(NP[case=X1,mod=X2,fin=f]/NP[case=X1,mod=X2,fin=f]) 、/、/_/_}} {< NP[case=nc,mod=nm,fin=f] {< NP[case=nc,mod=nm,fin=f] {NP[case=nc,mod=nm,fin=f] 三/三/_/_} {NP[case=nc,mod=nm,fin=f]\\NP[case=nc,mod=nm,fin=f] 年/年/_/_}} {NP[case=nc,mod=nm,fin=f]\\NP[case=nc,mod=nm,fin=f] 時/時/_/_}}} {(S[mod=X1,form=X2,fin=f]/S[mod=X1,form=X2,fin=f])\\NP[case=nc,mod=nm,fin=f] に/に/_/_}} {< S[mod=adn,form=base,fin=f] {> S[mod=nm,form=cont,fin=f] {>T S[mod=X1,form=X2,fin=X3]/(S[mod=X1,form=X2,fin=X3]\\NP[case=X1,mod=X2,fin=X3]) {NP[case=nc,mod=nm,fin=f] 担任/担任/_/_}} {S[mod=nm,form=cont,fin=f]\\NP[case=nc,mod=nm,fin=f] だっ/だっ/_/_}} {S[mod=adn,form=base,fin=f]\\S[mod=nm,form=cont,fin=f] た/た/_/_}}}} {> NP[case=nc,mod=nm,fin=f] {>B NP[case=X1,mod=X2,fin=f]/NP[case=X1,mod=X2,fin=f] {NP[case=X1,mod=X2,fin=f]/NP[case=X1,mod=X2,fin=f] 池田/池田/_/_} {>B NP[case=X1,mod=X2,fin=f]/NP[case=X1,mod=X2,fin=f] {NP[case=X1,mod=X2,fin=f]/NP[case=X1,mod=X2,fin=f] 弘子/弘子/_/_} {NP[case=X1,mod=X2,fin=f]/NP[case=X1,mod=X2,fin=f] 先生/先生/_/_}}} {< NP[case=nc,mod=nm,fin=f] {> NP[case=nc,mod=nm,fin=f] {NP[case=X1,mod=X2,fin=f]/NP[case=X1,mod=X2,fin=f] （/（/_/_} {> NP[case=nc,mod=nm,fin=f] {NP[case=X1,mod=X2,fin=f]/NP[case=X1,mod=X2,fin=f] ７/７/_/_} {NP[case=nc,mod=nm,fin=f] ５/５/_/_}}} {NP[case=nc,mod=nm,fin=f]\\NP[case=nc,mod=nm,fin=f] ）/）/_/_}}}} {NP[case=ga,mod=nm,fin=f]\\NP[case=nc,mod=nm,fin=f] は/は/_/_}}} {<B1 S[mod=nm,form=base,fin=f]\\NP[case=ga,mod=nm,fin=f] {S[mod=nm,form=cont,fin=f]\\NP[case=ga,mod=nm,fin=f] 違っ/違っ/_/_} {S[mod=nm,form=base,fin=f]\\S[mod=nm,form=cont,fin=f] た/た/_/_}}}} {S[mod=nm,form=base,fin=t]\\S[mod=nm,form=base,fin=f] 。/。/_/_}}\"\n",
    "    s = r\"{> NP {NP/NP 非常に/非常に/_/_} {< NP {NP 注意/注意/_/_} {NP\\NP い/い/_/_}}}\"\n",
    "    rotation = TreeRotation()\n",
    "    trees = [tree for _, _, tree in read_parsedtree(s)]\n",
    "    tree = rotation.rotate2left(trees[0])\n",
    "    print(ja_of(tree))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "S[mod=X1,form=X2,fin=X3]/((S[mod=X1,form=X2,fin=X3]\\NP[case=X1,mod=X2,fin=X3])\\NP[case=X1,mod=X2,fin=X3])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from depccg.cat import Category, Functor, Atom\n",
    "from depccg.unification import Unification\n",
    "x = Category.parse(r\"S[mod=X1,form=X2,fin=X3]/(S[mod=X1,form=X2,fin=X3]\\NP[case=X1,mod=X2,fin=X3])\")\n",
    "y = Category.parse(r\"(S[mod=X1,form=X2,fin=X3]\\NP[case=X1,mod=X2,fin=X3])/((S[mod=X1,form=X2,fin=X3]\\NP[case=X1,mod=X2,fin=X3])\\NP[case=X1,mod=X2,fin=X3])\")\n",
    "uni = Unification(\"a/b\", \"b/c\")\n",
    "uni(x, y)\n",
    "xy = Functor(uni[\"a\"], \"/\", uni[\"c\"])\n",
    "xy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
